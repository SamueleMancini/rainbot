{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO NOTE: TO PIPELINE IS VERY LENGTHY (>20 HOURS RUNTIME). TO FULLY REPRODUCE PLEASE ADAPT THE PATHS OF THE FOLDERS ACCORDING TO YOUR LOCAL STRUCTURE. THIS NOTEBOOK SHOWS THE MAIN STEPS TAKEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 & 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from typing import Tuple\n",
    "\n",
    "def crop_center(image: Image.Image, crop_size: Tuple[int, int] = (640, 640)) -> Image.Image:\n",
    "    width, height = image.size\n",
    "    crop_margin = 80\n",
    "    image = image.crop((crop_margin, 0, width - crop_margin*4, height))\n",
    "\n",
    "    crop_width, crop_height = crop_size\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    left = (img_width - crop_width) // 2\n",
    "    top = (img_height - crop_height) // 2\n",
    "    right = left + crop_width\n",
    "    bottom = top + crop_height\n",
    "\n",
    "    center_crop = image.crop((left, top, right, bottom))\n",
    "    return center_crop\n",
    "\n",
    "def process_images_in_folder(root_folder: str, crop_size: Tuple[int, int] = (640, 640)):\n",
    "    supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(supported_extensions):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        cropped_img = crop_center(img, crop_size)\n",
    "                        new_filename = f\"cropped_{file}\"\n",
    "                        save_path = os.path.join(subdir, new_filename)\n",
    "                        cropped_img.save(save_path)\n",
    "                        print(f\"Saved: {save_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {file_path}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "process_images_in_folder()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from typing import Tuple\n",
    "\n",
    "def crop_center(image: Image.Image, crop_size: Tuple[int, int] = (640, 640)) -> Image.Image:\n",
    "    \"\"\"\n",
    "    Crops the center of an image and resizes it to the specified dimensions.\n",
    "    \"\"\"\n",
    "    # First crop the margins\n",
    "    width, height = image.size\n",
    "    crop_margin = 80\n",
    "    image = image.crop((crop_margin, 0, width - crop_margin*4, height))\n",
    "    \n",
    "    # Then resize to target size\n",
    "    return image.resize(crop_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "def split_by_three(image: Image.Image) -> Tuple[Image.Image, Image.Image, Image.Image]:\n",
    "    \"\"\"\n",
    "    Splits an image into three equal vertical chunks.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    chunk_width = width // 3\n",
    "\n",
    "    chunk1 = image.crop((0, 0, chunk_width, height))\n",
    "    chunk2 = image.crop((chunk_width, 0, 2 * chunk_width, height))\n",
    "    chunk3 = image.crop((2 * chunk_width, 0, width, height))\n",
    "\n",
    "    return chunk1, chunk2, chunk3\n",
    "\n",
    "def process_images_in_folder(root_folder: str, crop_size: Tuple[int, int] = (640, 640)):\n",
    "    supported_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp')\n",
    "\n",
    "    for subdir, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(supported_extensions):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img1, img2, img3 = split_by_three(img)\n",
    "                        for i, int_img in enumerate([img1, img2, img3]):\n",
    "                            cropped_img = crop_center(int_img, crop_size)\n",
    "                            new_filename = f\"cropped_{i}_{file}\"\n",
    "                            save_path = os.path.join(subdir, new_filename)\n",
    "                            cropped_img.save(save_path)\n",
    "                            print(f\"Saved: {save_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {file_path}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "process_images_in_folder()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment using SegFormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andreafabbricatore/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-23 20:03:29.202551: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748023409.221709  772778 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748023409.227485  772778 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748023409.243207  772778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748023409.243224  772778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748023409.243226  772778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748023409.243228  772778 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "/home/andreafabbricatore/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/andreafabbricatore/.local/lib/python3.10/site-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import SegformerFeatureExtractor, SegformerForSemanticSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "IMAGE_DIR = \"input_images\"\n",
    "OUTPUT_DIR = \"segmented_output\"\n",
    "MODEL_NAME = \"nvidia/segformer-b0-finetuned-cityscapes-768-768\"\n",
    "\n",
    "# Cityscapes class mapping\n",
    "CITYSCAPES_ID2LABEL = {\n",
    "    0: 'road', 1: 'sidewalk', 2: 'building', 3: 'wall', 4: 'fence',\n",
    "    5: 'pole', 6: 'traffic_light', 7: 'traffic_sign', 8: 'vegetation', 9: 'terrain',\n",
    "    10: 'sky', 11: 'person', 12: 'rider', 13: 'car', 14: 'truck',\n",
    "    15: 'bus', 16: 'train', 17: 'motorcycle', 18: 'bicycle',\n",
    "}\n",
    "\n",
    "# === SETUP ===\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "for class_name in CITYSCAPES_ID2LABEL.values():\n",
    "    os.makedirs(os.path.join(OUTPUT_DIR, class_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(MODEL_NAME)\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(MODEL_NAME).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_save(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_np = np.array(image)\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # (1, num_classes, h/4, w/4)\n",
    "        upsampled_logits = torch.nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=image.size[::-1],  # (H, W)\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        predicted = upsampled_logits.argmax(dim=1)[0].cpu().numpy()  # (H, W)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "\n",
    "    for class_idx, class_name in CITYSCAPES_ID2LABEL.items():\n",
    "        mask = (predicted == class_idx).astype(np.uint8)\n",
    "\n",
    "        if np.any(mask):\n",
    "            # Apply mask to original image\n",
    "            masked_img = image_np.copy()\n",
    "            masked_img[mask == 0] = 0  # Zero out everything except target class\n",
    "\n",
    "            masked_pil = Image.fromarray(masked_img)\n",
    "            save_path = os.path.join(OUTPUT_DIR, class_name, f\"{base_name}_{class_name}.png\")\n",
    "            masked_pil.save(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory):\n",
    "    \"\"\"Process all image files in a directory and its subdirectories.\"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        for filename in tqdm(image_files, desc=f\"Processing {os.path.basename(root)}\"):\n",
    "            segment_and_save(os.path.join(root, filename))\n",
    "\n",
    "# Process all images in IMAGE_DIR and its subdirectories\n",
    "process_directory(IMAGE_DIR)\n",
    "print(\"Done. Masks saved in:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove mostly black pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def check_black_pixels(image_path, threshold=0.95):\n",
    "    \"\"\"Check if an image has more than threshold% black pixels.\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        print(f\"Could not read image: {image_path}\")\n",
    "        return False\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Count black pixels (value < 10)\n",
    "    black_pixels = np.sum(gray < 10)\n",
    "    total_pixels = gray.size\n",
    "    \n",
    "    return (black_pixels / total_pixels) > threshold\n",
    "\n",
    "segments = CITYSCAPES_ID2LABEL.values()\n",
    "base_path = \"\"\n",
    "# Process all segments and splits\n",
    "for segment in segments:\n",
    "    print(f\"\\nProcessing {segment} segment...\")\n",
    "    dataset_path = Path(base_path) / segment / \"final_datasets\"\n",
    "    \n",
    "    for split in [\"train\", \"test\", \"val\"]:\n",
    "        split_path = dataset_path / split\n",
    "        if not split_path.exists():\n",
    "            continue\n",
    "            \n",
    "        countries = [d for d in os.listdir(split_path) if os.path.isdir(split_path / d)]\n",
    "        \n",
    "        for country in countries:\n",
    "            country_path = split_path / country\n",
    "            print(f\"\\nChecking {split}/{country}...\")\n",
    "            black_images = []\n",
    "            \n",
    "            for img_path in country_path.glob(\"*.png\"):\n",
    "                if check_black_pixels(img_path):\n",
    "                    black_images.append(img_path)\n",
    "            \n",
    "            if black_images:\n",
    "                print(f\"Found {len(black_images)} images with >95% black pixels in {country}\")\n",
    "                for img_path in black_images:\n",
    "                    os.remove(img_path)\n",
    "                    print(f\"  - Deleted: {img_path.name}\")\n",
    "            else:\n",
    "                print(f\"No images with >95% black pixels found in {country}\")\n",
    "\n",
    "print(\"\\n✅ Black pixel cleanup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank by segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store image scores\n",
    "image_scores = {}\n",
    "\n",
    "# Get all images from main dataset\n",
    "main_dataset_path = Path(base_path)\n",
    "for country in os.listdir(main_dataset_path):\n",
    "    country_path = main_dataset_path / country\n",
    "    if not country_path.is_dir():\n",
    "        continue\n",
    "        \n",
    "    # Initialize scores for all images in this country\n",
    "    for img_path in country_path.glob(\"*.png\"):\n",
    "        image_scores[img_path] = 0\n",
    "\n",
    "# Check each segment for matching images\n",
    "for segment in segments:\n",
    "    segment_path = Path(base_path) / segment \n",
    "    if not segment_path.exists():\n",
    "        continue\n",
    "        \n",
    "    for country in os.listdir(segment_path):\n",
    "        country_segment_path = segment_path / country\n",
    "        if not country_segment_path.is_dir():\n",
    "            continue\n",
    "            \n",
    "        # For each image in the segment\n",
    "        for seg_img_path in country_segment_path.glob(\"*.png\"):\n",
    "            # Extract original image name (remove segment suffix)\n",
    "            original_name = seg_img_path.stem.split(f\"_{segment}\")[0] + \".png\"\n",
    "            original_path = main_dataset_path / country / original_name\n",
    "            \n",
    "            # If original image exists, increment its score\n",
    "            if original_path in image_scores:\n",
    "                image_scores[original_path] += 1\n",
    "\n",
    "\n",
    "# Sort image scores in ascending order\n",
    "sorted_scores = sorted(image_scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for final dataset\n",
    "import shutil\n",
    "\n",
    "\n",
    "final_dataset_path = Path(base_path) / \"final_dataset\"\n",
    "final_dataset_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Get top 450 images\n",
    "top_images = sorted_scores[:450]\n",
    "\n",
    "# Copy top images to final dataset\n",
    "for img_path, score in tqdm(top_images, desc=\"Copying top images\"):\n",
    "    # Create country directory if it doesn't exist\n",
    "    country_dir = final_dataset_path / img_path.parent.name\n",
    "    country_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Copy image to final dataset\n",
    "    shutil.copy2(img_path, country_dir / img_path.name)\n",
    "\n",
    "print(f\"Created final dataset with {len(top_images)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train, test, val directories\n",
    "train_path = final_dataset_path / \"train\"\n",
    "test_path = final_dataset_path / \"test\" \n",
    "val_path = final_dataset_path / \"val\"\n",
    "\n",
    "for path in [train_path, test_path, val_path]:\n",
    "    path.mkdir(exist_ok=True)\n",
    "\n",
    "# Get list of all images\n",
    "all_images = list(final_dataset_path.glob(\"**/*.png\"))\n",
    "all_images = [img for img in all_images if img.parent.name != \"train\" and img.parent.name != \"test\" and img.parent.name != \"val\"]\n",
    "\n",
    "# Shuffle images\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(all_images)\n",
    "\n",
    "# Calculate split sizes\n",
    "total_images = len(all_images)\n",
    "train_size = int(0.8 * total_images)\n",
    "test_size = int(0.1 * total_images)\n",
    "val_size = total_images - train_size - test_size\n",
    "\n",
    "# Split images\n",
    "train_images = all_images[:train_size]\n",
    "test_images = all_images[train_size:train_size + test_size]\n",
    "val_images = all_images[train_size + test_size:]\n",
    "\n",
    "# Function to copy images to split directories\n",
    "def copy_to_split(images, split_path):\n",
    "    for img_path in tqdm(images, desc=f\"Copying to {split_path.name}\"):\n",
    "        # Create country directory in split\n",
    "        country_dir = split_path / img_path.parent.name\n",
    "        country_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy2(img_path, country_dir / img_path.name)\n",
    "\n",
    "# Copy images to respective splits\n",
    "copy_to_split(train_images, train_path)\n",
    "copy_to_split(test_images, test_path)\n",
    "copy_to_split(val_images, val_path)\n",
    "\n",
    "print(f\"Created splits:\")\n",
    "print(f\"Train: {len(train_images)} images\")\n",
    "print(f\"Test: {len(test_images)} images\")\n",
    "print(f\"Val: {len(val_images)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "segmented_base = Path(\"\")  # base with segment_class/country/image.png\n",
    "original_split_base = Path(\"\")        # where original split is (train/test/val/country/*.png)\n",
    "segmented_final = Path(\"\")  # destination\n",
    "\n",
    "# Get list of segment classes\n",
    "segment_classes = ['road', 'vegetation', 'terrain']\n",
    "\n",
    "# For each segment class\n",
    "for segment_class in segment_classes:\n",
    "    print(f\"\\nProcessing segment class: {segment_class}\")\n",
    "\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_images = list((original_split_base / split).glob(\"*/*.png\"))  # country/image.png\n",
    "\n",
    "        for img_path in tqdm(split_images, desc=f\"{segment_class} → {split}\"):\n",
    "            country = img_path.parent.name\n",
    "            img_name = img_path.name\n",
    "            segmented_img_path = segmented_base / segment_class / country / img_name\n",
    "\n",
    "            if segmented_img_path.exists():\n",
    "                dest_dir = segmented_final / segment_class / split / country\n",
    "                dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(segmented_img_path, dest_dir / img_name)\n",
    "            else:\n",
    "                print(f\"⚠️ Missing segmented image: {segmented_img_path}\")\n",
    "\n",
    "    print(f\"✅ Done with segment class: {segment_class}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(base_path, dataset_type=\"countries\"):\n",
    "    \"\"\"\n",
    "    Balance datasets by reducing all classes to match the minimum class size\n",
    "    while maintaining the 80:10:10 train/val/test split ratio\n",
    "    \"\"\"\n",
    "    print(f\"\\nBalancing {dataset_type} dataset...\")\n",
    "    \n",
    "    if dataset_type == \"countries\":\n",
    "        # Get all segments\n",
    "        segments = ['road', 'vegetation', 'terrain']\n",
    "    else:\n",
    "        segments = os.listdir(base_path)\n",
    "\n",
    "    for segment in segments:\n",
    "        print(f\"\\nProcessing {segment}...\")\n",
    "        \n",
    "        # Determine paths based on dataset type\n",
    "        data_path = os.path.join(base_path, segment, \"final_datasets\")\n",
    "        \n",
    "        # Find minimum total class size across all splits\n",
    "        min_total = float('inf')\n",
    "        min_class = None\n",
    "        \n",
    "        # Get all classes from train directory\n",
    "        train_path = os.path.join(data_path, \"train\")\n",
    "        if not os.path.exists(train_path):\n",
    "            continue\n",
    "            \n",
    "        classes = os.listdir(train_path)\n",
    "        for class_name in classes:\n",
    "            total_images = 0\n",
    "            for split in ['train', 'val', 'test']:\n",
    "                split_path = os.path.join(data_path, split, class_name)\n",
    "                if os.path.exists(split_path):\n",
    "                    total_images += len(os.listdir(split_path))\n",
    "            \n",
    "            if total_images < min_total:\n",
    "                min_total = total_images\n",
    "                min_class = class_name\n",
    "        \n",
    "        if min_total == float('inf'):\n",
    "            print(f\"No valid classes found for {segment}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"Minimum total class size: {min_total} ({min_class})\")\n",
    "        \n",
    "        # Calculate target sizes for each split\n",
    "        train_target = int(min_total * 0.8)\n",
    "        val_target = int(min_total * 0.1)\n",
    "        test_target = int(min_total * 0.1)\n",
    "        \n",
    "        # Balance each class\n",
    "        for class_name in classes:\n",
    "            for split, target_size in [('train', train_target), ('val', val_target), ('test', test_target)]:\n",
    "                split_path = os.path.join(data_path, split, class_name)\n",
    "                if not os.path.exists(split_path):\n",
    "                    continue\n",
    "                    \n",
    "                images = os.listdir(split_path)\n",
    "                if len(images) > target_size:\n",
    "                    # Randomly select images to keep\n",
    "                    images_to_keep = random.sample(images, target_size)\n",
    "                    \n",
    "                    # Remove excess images\n",
    "                    for img in images:\n",
    "                        if img not in images_to_keep:\n",
    "                            os.remove(os.path.join(split_path, img))\n",
    "                    \n",
    "                    print(f\"Reduced {class_name} {split} from {len(images)} to {target_size} images\")\n",
    "\n",
    "# Balance both datasets\n",
    "balance_dataset(base_path, \"countries\")\n",
    "\n",
    "print(\"\\n✅ Dataset balancing complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
