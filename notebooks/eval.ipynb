{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    top_k_accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c591a60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2edc86c",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785beda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES = [\"Albania\",\"Andorra\",\"Argentina\",\"Australia\",\"Austria\",\"Bangladesh\",\"Belgium\",\"Bhutan\",\"Bolivia\",\"Botswana\",\"Brazil\",\"Bulgaria\",\"Cambodia\",\"Canada\",\"Chile\",\"Colombia\",\"Croatia\",\"Czechia\",\"Denmark\",\"Dominican Republic\",\"Ecuador\",\"Estonia\",\"Eswatini\",\"Finland\",\"France\",\"Germany\",\"Ghana\",\"Greece\",\"Greenland\",\"Guatemala\",\"Hungary\",\"Iceland\",\"Indonesia\",\"Ireland\",\"Israel\",\"Italy\",\"Japan\",\"Jordan\",\"Kenya\",\"Kyrgyzstan\",\"Latvia\",\"Lesotho\",\"Lithuania\",\"Luxembourg\",\"Malaysia\",\"Mexico\",\"Mongolia\",\"Montenegro\",\"Netherlands\",\"New Zealand\",\"Nigeria\",\"North Macedonia\",\"Norway\",\"Palestine\",\"Peru\",\"Philippines\",\"Poland\",\"Portugal\",\"Romania\",\"Russia\",\"Senegal\",\"Serbia\",\"Singapore\",\"Slovakia\",\"Slovenia\",\"South Africa\",\"South Korea\",\"Spain\",\"Sri Lanka\",\"Sweden\",\"Switzerland\",\"Taiwan\",\"Thailand\",\"Turkey\",\"Ukraine\",\"United Arab Emirates\",\"United Kingdom\",\"United States\",\"Uruguay\"]\n",
    "num_classes = len(COUNTRIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ce706",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountryImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        for idx, country in enumerate(COUNTRIES):\n",
    "            country_dir = root_dir / country\n",
    "            for img_file in country_dir.iterdir():\n",
    "                if img_file.suffix.lower() in (\".jpg\", \".jpeg\", \".png\"):\n",
    "                    self.samples.append((img_file, idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path, label = self.samples[i]\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57d59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(root_dir, batch_size=32):\n",
    "    dataset = CountryImageDataset(root_dir, transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bc6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = get_dataloaders(\" \", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9faf932",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644460ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 79)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec04ff8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d475a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "def evaluate_model(model, data_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Runs model on data_loader and returns:\n",
    "      - avg_loss: float\n",
    "      - top1_acc: float\n",
    "      - all_targets: np.array shape (N,)\n",
    "      - all_preds:   np.array shape (N,)\n",
    "      - all_probs:   np.array shape (N, num_classes)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total_samples = 0.0, 0, 0\n",
    "    all_preds, all_targets, all_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss    = criterion(outputs, labels)\n",
    "\n",
    "            # accumulate loss & top‐1 accuracy\n",
    "            batch_size = imgs.size(0)\n",
    "            total_loss    += loss.item() * batch_size\n",
    "            preds         = outputs.argmax(dim=1)\n",
    "            total_correct += (preds == labels).sum().item()\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # store for detailed metrics\n",
    "            all_probs.append(softmax(outputs).cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(labels.cpu().numpy())\n",
    "\n",
    "    # flatten\n",
    "    all_probs   = np.vstack(all_probs)\n",
    "    all_preds   = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    top1_acc = total_correct / total_samples\n",
    "\n",
    "    return avg_loss, top1_acc, all_targets, all_preds, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a33952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(all_targets, all_preds, all_probs, class_names):\n",
    "    \"\"\"\n",
    "    Given flattened targets, preds, and probs:\n",
    "      - prints Top-3/5 accuracy\n",
    "      - prints classification report\n",
    "      - plots normalized confusion matrix\n",
    "    \"\"\"\n",
    "    top3 = top_k_accuracy_score(all_targets, all_probs, k=3)\n",
    "    top5 = top_k_accuracy_score(all_targets, all_probs, k=5)\n",
    "    print(f\"Top-3 Accuracy: {top3:.4f}\")\n",
    "    print(f\"Top-5 Accuracy: {top5:.4f}\\n\")\n",
    "\n",
    "    report = classification_report(\n",
    "        all_targets, all_preds,\n",
    "        target_names=class_names,\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721193c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(all_targets, all_preds, class_names):\n",
    "    \n",
    "    cm = confusion_matrix(all_targets, all_preds, normalize='true')\n",
    "    fig, ax = plt.subplots(figsize=(12,12))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.set_title(\"Normalized Confusion Matrix\")\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    ticks = np.arange(len(class_names))\n",
    "    ax.set_xticks(ticks); ax.set_yticks(ticks)\n",
    "    ax.set_xticklabels(class_names, rotation=90)\n",
    "    ax.set_yticklabels(class_names)\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8055ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample_predictions(all_targets, all_probs, class_names, n=5):\n",
    "    \"\"\"\n",
    "    Prints n random examples of true label vs top-3 predictions+probs.\n",
    "    \"\"\"\n",
    "    total = len(all_targets)\n",
    "    print(f\"\\nSample predictions ({n} examples):\\n\")\n",
    "    idxs = np.random.choice(total, size=n, replace=False)\n",
    "    for i in idxs:\n",
    "        true_lbl = class_names[all_targets[i]]\n",
    "        probs_i  = all_probs[i]\n",
    "        topk     = probs_i.argsort()[::-1][:3]\n",
    "        topk_str = \", \".join(f\"{class_names[k]} ({probs_i[k]:.2f})\" for k in topk)\n",
    "        print(f\"True: {true_lbl:20s}  ↔  Pred Top-3: {topk_str}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
